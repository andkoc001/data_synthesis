# Data synthesis - meteorites 
Assignment project for Programming for Data Analysis module at GMIT, 2019.

Lecturer: dr Brian McGinley

>Author: **Andrzej Kocielski**  
>Github: [andkoc001](https://github.com/andkoc001/)  
>Email: G00376291@gmit.ie, and.koc001@gmail.com

Created: 16-11-2019

___
## Introduction

This is my assignment project to Programming for Data Analysis module, Galway-Mayo Institute of Technology, 2019.

This GitHub repository documents my research, project progress (git version control) and findings of the _meteorites_ data synthesis. 

## Assignment objectives

The project concerns a creation of a model of a real-world phenomenon. It involves subject research, identification of key parameters and variables affecting the phenomenon, as well as relationship between them. The projects involves also running a simulation of the model and synthesising the the variables in a dataset. 

I have chosen to research and analyse the __**falling meteorites**__ phenomenon. Because of the complexity, a number of simplifiaction has been applied for this project. More details can be found in the Notebook.

The high level objectives of the project are as follows.
- To choose a real-world phenomenon that can be measured,
- Investigate variables - distributions and relationship with each other,
- Simulate / synthesise a dataset describing the phenomenon - Jupyter Notebook,
- Document the research and the data synthesis.


The detailed project instructions: <https://github.com/brianmcgmit/ProgDA/raw/master/ProgDA_Project.pdf>.

This project is intended to further familiarisation with data analytics. The project will allow to get practical understanding of handling data in Python environment. It is also intended to get familiar with the analytical tools. The tools used in the project include Python language with additional libraries like Pandas, Numpy, Seaborn, etc. as well as Jupyter Notbook.

It is also intended to gain knowledge and understanding through practical exercises about data analysis algorithms and methods. These in particular, would include linear regression, grouping, correlations, classification and pattern recognition.

As an outcome of the project, it is hoped to become more proficient in data analytics concepts and methods, including data types and structures handling, data splicing, plots generation and interpretation.

As it is a learning exercise for me, I have made attempt to comment various functionalities not only for readability but also for my future reference.

___
## Project delivery

The project is delivered via this GitHub [repository](https://github.com/andkoc001/data_synthesis.git).

This README.md file contains background information and introduction to the project. It should be read in conjunction with the Jupyter Notebook [data_synth_1.ipynb](https://github.com/andkoc001/data_synthesis/blob/master/data_synth_1.ipynb), where the data synthesis is conducted. 

In the notebook I have incorporated the research and described the project progress. It is illustrated the applied concepts and methods together with relevant code snippets. The notebook includes also the calculated outputs and plots with accompanied description. Finally, inside the notebook I have included also references to sources being consulted for this assignment.


### Viewing the Notebook

For viewing the notebook online, it is recommended to use Jupyter Notebooks viewer, [nbviewer](https://nbviewer.jupyter.org/). Paste the link to the notebook to be inspected into provided field.

___
## Tools used

_Python_ programming language is acclaimed for its capacity of handling large amount of data in scientific community of different specialisation. Its natural functionality has been extended by development of external libraries dedicated for specific purposes. Throught the project I used the following libraries: 
- _NumPy_ - used for scientific calculations in Python; it allows, among others, to perform numerical calculations or random numbers generation.
- _Pandas_ - used for data analysis and provides functionalities and data structures needed to work with structured datasets.
- _Matplotlib_ - for producing plotting.
- _Seaborn_ - used for data visualization based on matplotlib.

The project was conducted in _Jupyter Notebook_ (_Jupyter Lab_) environment, that provides interactive, web-based environment for data science and scientific computing.

___
## References

General, high-level, reference sources are listed below. References to specific problems are included in the Notebook.

### Project and the data set related

- GMIT Programing for Data Analysis module materials on Moodle platform (access may be restricted for staff and students): <https://learnonline.gmit.ie/course/view.php?id=1127>

### Python environment

- [Python 3 documentation](https://docs.python.org/3/)
- [NumPy documentation](https://numpy.org/doc/)
- [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/)
- [Matplotlib documentation](https://matplotlib.org/contents.html)
- [Seaborn documentation](https://seaborn.pydata.org/)
- [Jupyter documentation](https://jupyter.org/documentation)

___
Andrzej Kocielski

